{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda98f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               6400      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,769\n",
      "Trainable params: 16,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.7036 - accuracy: 0.5666 - val_loss: 0.6573 - val_accuracy: 0.6587\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.6637 - accuracy: 0.6305 - val_loss: 0.6287 - val_accuracy: 0.7015\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.6441 - accuracy: 0.6555 - val_loss: 0.6088 - val_accuracy: 0.7256\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.6307 - accuracy: 0.6745 - val_loss: 0.5948 - val_accuracy: 0.7292\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.6218 - accuracy: 0.6821 - val_loss: 0.5846 - val_accuracy: 0.7315\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.6114 - accuracy: 0.6914 - val_loss: 0.5773 - val_accuracy: 0.7328\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6982 - val_loss: 0.5716 - val_accuracy: 0.7336\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.7008 - val_loss: 0.5673 - val_accuracy: 0.7346\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5998 - accuracy: 0.7029 - val_loss: 0.5642 - val_accuracy: 0.7349\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.7056 - val_loss: 0.5618 - val_accuracy: 0.7341\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5919 - accuracy: 0.7095 - val_loss: 0.5597 - val_accuracy: 0.7365\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5911 - accuracy: 0.7078 - val_loss: 0.5582 - val_accuracy: 0.7372\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.7100 - val_loss: 0.5569 - val_accuracy: 0.7378\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.7102 - val_loss: 0.5557 - val_accuracy: 0.7372\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5871 - accuracy: 0.7114 - val_loss: 0.5546 - val_accuracy: 0.7383\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.7103 - val_loss: 0.5538 - val_accuracy: 0.7375\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5820 - accuracy: 0.7122 - val_loss: 0.5531 - val_accuracy: 0.7375\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5845 - accuracy: 0.7120 - val_loss: 0.5524 - val_accuracy: 0.7378\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5815 - accuracy: 0.7162 - val_loss: 0.5518 - val_accuracy: 0.7372\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5802 - accuracy: 0.7153 - val_loss: 0.5512 - val_accuracy: 0.7367\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5795 - accuracy: 0.7160 - val_loss: 0.5507 - val_accuracy: 0.7367\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5773 - accuracy: 0.7168 - val_loss: 0.5504 - val_accuracy: 0.7367\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5797 - accuracy: 0.7141 - val_loss: 0.5500 - val_accuracy: 0.7367\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5758 - accuracy: 0.7175 - val_loss: 0.5496 - val_accuracy: 0.7367\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5797 - accuracy: 0.7159 - val_loss: 0.5493 - val_accuracy: 0.7367\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5794 - accuracy: 0.7142 - val_loss: 0.5490 - val_accuracy: 0.7367\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5770 - accuracy: 0.7163 - val_loss: 0.5487 - val_accuracy: 0.7362\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5775 - accuracy: 0.7142 - val_loss: 0.5485 - val_accuracy: 0.7359\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5785 - accuracy: 0.7167 - val_loss: 0.5483 - val_accuracy: 0.7357\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5762 - accuracy: 0.7159 - val_loss: 0.5481 - val_accuracy: 0.7357\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5764 - accuracy: 0.7178 - val_loss: 0.5479 - val_accuracy: 0.7359\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5751 - accuracy: 0.7183 - val_loss: 0.5477 - val_accuracy: 0.7359\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5764 - accuracy: 0.7166 - val_loss: 0.5475 - val_accuracy: 0.7359\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5731 - accuracy: 0.7195 - val_loss: 0.5474 - val_accuracy: 0.7359\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5730 - accuracy: 0.7187 - val_loss: 0.5473 - val_accuracy: 0.7367\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5729 - accuracy: 0.7162 - val_loss: 0.5471 - val_accuracy: 0.7367\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5701 - accuracy: 0.7201 - val_loss: 0.5469 - val_accuracy: 0.7367\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5742 - accuracy: 0.7178 - val_loss: 0.5467 - val_accuracy: 0.7367\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5717 - accuracy: 0.7180 - val_loss: 0.5466 - val_accuracy: 0.7359\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5751 - accuracy: 0.7193 - val_loss: 0.5465 - val_accuracy: 0.7359\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5723 - accuracy: 0.7180 - val_loss: 0.5464 - val_accuracy: 0.7349\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5728 - accuracy: 0.7184 - val_loss: 0.5463 - val_accuracy: 0.7359\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5727 - accuracy: 0.7175 - val_loss: 0.5463 - val_accuracy: 0.7359\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5723 - accuracy: 0.7190 - val_loss: 0.5461 - val_accuracy: 0.7357\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5721 - accuracy: 0.7187 - val_loss: 0.5461 - val_accuracy: 0.7357\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5706 - accuracy: 0.7164 - val_loss: 0.5460 - val_accuracy: 0.7354\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5710 - accuracy: 0.7215 - val_loss: 0.5459 - val_accuracy: 0.7357\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5704 - accuracy: 0.7212 - val_loss: 0.5458 - val_accuracy: 0.7357\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5726 - accuracy: 0.7180 - val_loss: 0.5457 - val_accuracy: 0.7357\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5722 - accuracy: 0.7174 - val_loss: 0.5457 - val_accuracy: 0.7357\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5688 - accuracy: 0.7197 - val_loss: 0.5456 - val_accuracy: 0.7357\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5692 - accuracy: 0.7201 - val_loss: 0.5456 - val_accuracy: 0.7365\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5698 - accuracy: 0.7211 - val_loss: 0.5455 - val_accuracy: 0.7357\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5697 - accuracy: 0.7188 - val_loss: 0.5454 - val_accuracy: 0.7357\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5712 - accuracy: 0.7205 - val_loss: 0.5454 - val_accuracy: 0.7365\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5707 - accuracy: 0.7197 - val_loss: 0.5453 - val_accuracy: 0.7357\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5697 - accuracy: 0.7211 - val_loss: 0.5453 - val_accuracy: 0.7357\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5700 - accuracy: 0.7212 - val_loss: 0.5452 - val_accuracy: 0.7365\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5692 - accuracy: 0.7217 - val_loss: 0.5452 - val_accuracy: 0.7357\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5698 - accuracy: 0.7211 - val_loss: 0.5451 - val_accuracy: 0.7365\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5702 - accuracy: 0.7188 - val_loss: 0.5450 - val_accuracy: 0.7362\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5693 - accuracy: 0.7191 - val_loss: 0.5451 - val_accuracy: 0.7367\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5697 - accuracy: 0.7222 - val_loss: 0.5451 - val_accuracy: 0.7367\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5699 - accuracy: 0.7213 - val_loss: 0.5450 - val_accuracy: 0.7367\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5693 - accuracy: 0.7216 - val_loss: 0.5450 - val_accuracy: 0.7365\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5678 - accuracy: 0.7196 - val_loss: 0.5450 - val_accuracy: 0.7365\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5661 - accuracy: 0.7226 - val_loss: 0.5449 - val_accuracy: 0.7365\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5692 - accuracy: 0.7212 - val_loss: 0.5449 - val_accuracy: 0.7365\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5691 - accuracy: 0.7225 - val_loss: 0.5449 - val_accuracy: 0.7365\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5681 - accuracy: 0.7201 - val_loss: 0.5449 - val_accuracy: 0.7372\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5676 - accuracy: 0.7214 - val_loss: 0.5448 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5667 - accuracy: 0.7222 - val_loss: 0.5448 - val_accuracy: 0.7362\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5686 - accuracy: 0.7204 - val_loss: 0.5448 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5687 - accuracy: 0.7224 - val_loss: 0.5447 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5673 - accuracy: 0.7225 - val_loss: 0.5447 - val_accuracy: 0.7359\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5660 - accuracy: 0.7220 - val_loss: 0.5447 - val_accuracy: 0.7359\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5667 - accuracy: 0.7215 - val_loss: 0.5447 - val_accuracy: 0.7362\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5646 - accuracy: 0.7227 - val_loss: 0.5446 - val_accuracy: 0.7359\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5680 - accuracy: 0.7189 - val_loss: 0.5446 - val_accuracy: 0.7362\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5644 - accuracy: 0.7229 - val_loss: 0.5445 - val_accuracy: 0.7372\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5676 - accuracy: 0.7197 - val_loss: 0.5445 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5672 - accuracy: 0.7235 - val_loss: 0.5445 - val_accuracy: 0.7367\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5667 - accuracy: 0.7222 - val_loss: 0.5444 - val_accuracy: 0.7367\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5641 - accuracy: 0.7227 - val_loss: 0.5444 - val_accuracy: 0.7367\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5664 - accuracy: 0.7200 - val_loss: 0.5444 - val_accuracy: 0.7359\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5661 - accuracy: 0.7236 - val_loss: 0.5444 - val_accuracy: 0.7367\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5639 - accuracy: 0.7228 - val_loss: 0.5443 - val_accuracy: 0.7367\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5676 - accuracy: 0.7225 - val_loss: 0.5443 - val_accuracy: 0.7365\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5646 - accuracy: 0.7226 - val_loss: 0.5443 - val_accuracy: 0.7367\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5665 - accuracy: 0.7223 - val_loss: 0.5443 - val_accuracy: 0.7367\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5673 - accuracy: 0.7224 - val_loss: 0.5443 - val_accuracy: 0.7375\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5651 - accuracy: 0.7210 - val_loss: 0.5442 - val_accuracy: 0.7372\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5630 - accuracy: 0.7227 - val_loss: 0.5442 - val_accuracy: 0.7372\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 2s 6ms/step - loss: 0.5673 - accuracy: 0.7222 - val_loss: 0.5442 - val_accuracy: 0.7372\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5664 - accuracy: 0.7225 - val_loss: 0.5442 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5640 - accuracy: 0.7241 - val_loss: 0.5442 - val_accuracy: 0.7372\n",
      "Epoch 97/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5650 - accuracy: 0.7206 - val_loss: 0.5442 - val_accuracy: 0.7372\n",
      "Epoch 98/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5656 - accuracy: 0.7243 - val_loss: 0.5441 - val_accuracy: 0.7372\n",
      "Epoch 99/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5646 - accuracy: 0.7217 - val_loss: 0.5441 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5655 - accuracy: 0.7244 - val_loss: 0.5441 - val_accuracy: 0.7372\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import and read the charity_data.csv\n",
    "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
    "application_df = pd.read_csv(url)\n",
    "\n",
    "# Create a new DataFrame with only the columns needed for modeling\n",
    "model_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
    "\n",
    "# Determine the number of unique values in each column\n",
    "unique_value_counts = model_df.nunique()\n",
    "\n",
    "# Binning for APPLICATION_TYPE column\n",
    "counts = model_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "application_types_to_replace = list(counts[counts < 500].index)\n",
    "model_df[\"APPLICATION_TYPE\"] = model_df[\"APPLICATION_TYPE\"].replace(application_types_to_replace, \"Other\")\n",
    "\n",
    "# Binning for CLASSIFICATION column\n",
    "counts_binning = model_df[\"CLASSIFICATION\"].value_counts()\n",
    "counts_classification = counts_binning[counts_binning > 1]\n",
    "classifications_to_replace = list(counts_binning[counts_binning < 100].index)\n",
    "model_df[\"CLASSIFICATION\"] = model_df[\"CLASSIFICATION\"].replace(classifications_to_replace, \"Other\")\n",
    "\n",
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "model_df = pd.get_dummies(model_df, dtype=np.float32, sparse=True)\n",
    "\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "y = model_df[\"IS_SUCCESSFUL\"].values\n",
    "X = model_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 128\n",
    "hidden_nodes_layer2 = 64\n",
    "hidden_nodes_layer3 = 32\n",
    "nn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"Adagrad\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, validation_split=0.15, epochs=100, batch_size=64, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7103a16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5542 - accuracy: 0.7299 - 637ms/epoch - 2ms/step\n",
      "Loss: 0.5541941523551941, Accuracy: 0.729912519454956\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "# from google.colab import files\n",
    "\n",
    "nn.save('AlphabetSoupCharity_final.h5')\n",
    "# files.download('AlphabetSoupCharity_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7e34e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Loss: 0.55\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {model_accuracy:.2f}\\nLoss: {model_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <!-- may help improve the model's performance -->\n",
    "# Increase the number of hidden nodes in each layer\n",
    "# Add more hidden layers\n",
    "# Increase the number of epochs to allow the model to train for longer\n",
    "# Use a different optimizer like \"Adagrad\" or \"RMSprop\"\n",
    "#Uses the same early stopping callback as before to stop the training if the validation loss does not improve \n",
    "# for 10 epochs. These changes should help improve the performance of the model.\n",
    "# Add dropout layers to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model has three hidden layers with 128, 64, and 32 nodes, respectively. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
