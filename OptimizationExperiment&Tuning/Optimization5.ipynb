{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee2d336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 0.5803 - accuracy: 0.7166 - val_loss: 0.5485 - val_accuracy: 0.7393\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5613 - accuracy: 0.7264 - val_loss: 0.5462 - val_accuracy: 0.7354\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5549 - accuracy: 0.7287 - val_loss: 0.5475 - val_accuracy: 0.7339\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 2s 6ms/step - loss: 0.5542 - accuracy: 0.7290 - val_loss: 0.5450 - val_accuracy: 0.7359\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5530 - accuracy: 0.7314 - val_loss: 0.5480 - val_accuracy: 0.7359\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5521 - accuracy: 0.7317 - val_loss: 0.5441 - val_accuracy: 0.7341\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5499 - accuracy: 0.7303 - val_loss: 0.5429 - val_accuracy: 0.7362\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5502 - accuracy: 0.7306 - val_loss: 0.5446 - val_accuracy: 0.7370\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5487 - accuracy: 0.7325 - val_loss: 0.5415 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5486 - accuracy: 0.7322 - val_loss: 0.5434 - val_accuracy: 0.7365\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5468 - accuracy: 0.7315 - val_loss: 0.5417 - val_accuracy: 0.7365\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5470 - accuracy: 0.7330 - val_loss: 0.5453 - val_accuracy: 0.7328\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5478 - accuracy: 0.7331 - val_loss: 0.5437 - val_accuracy: 0.7349\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5460 - accuracy: 0.7330 - val_loss: 0.5427 - val_accuracy: 0.7365\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5450 - accuracy: 0.7313 - val_loss: 0.5422 - val_accuracy: 0.7341\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5453 - accuracy: 0.7324 - val_loss: 0.5441 - val_accuracy: 0.7365\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5460 - accuracy: 0.7333 - val_loss: 0.5430 - val_accuracy: 0.7357\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5451 - accuracy: 0.7333 - val_loss: 0.5426 - val_accuracy: 0.7359\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5454 - accuracy: 0.7347 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5437 - accuracy: 0.7339 - val_loss: 0.5434 - val_accuracy: 0.7328\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5449 - accuracy: 0.7324 - val_loss: 0.5420 - val_accuracy: 0.7352\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5438 - accuracy: 0.7339 - val_loss: 0.5408 - val_accuracy: 0.7354\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5430 - accuracy: 0.7354 - val_loss: 0.5459 - val_accuracy: 0.7336\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 2s 6ms/step - loss: 0.5434 - accuracy: 0.7356 - val_loss: 0.5416 - val_accuracy: 0.7365\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5433 - accuracy: 0.7346 - val_loss: 0.5417 - val_accuracy: 0.7352\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5435 - accuracy: 0.7348 - val_loss: 0.5427 - val_accuracy: 0.7357\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5431 - accuracy: 0.7348 - val_loss: 0.5419 - val_accuracy: 0.7349\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5424 - accuracy: 0.7350 - val_loss: 0.5407 - val_accuracy: 0.7383\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5416 - accuracy: 0.7348 - val_loss: 0.5422 - val_accuracy: 0.7349\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5435 - accuracy: 0.7355 - val_loss: 0.5417 - val_accuracy: 0.7359\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5411 - accuracy: 0.7344 - val_loss: 0.5436 - val_accuracy: 0.7344\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5421 - accuracy: 0.7359 - val_loss: 0.5417 - val_accuracy: 0.7344\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5409 - accuracy: 0.7361 - val_loss: 0.5421 - val_accuracy: 0.7352\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5411 - accuracy: 0.7342 - val_loss: 0.5399 - val_accuracy: 0.7354\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5408 - accuracy: 0.7352 - val_loss: 0.5413 - val_accuracy: 0.7388\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5406 - accuracy: 0.7344 - val_loss: 0.5416 - val_accuracy: 0.7362\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5407 - accuracy: 0.7373 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5404 - accuracy: 0.7350 - val_loss: 0.5427 - val_accuracy: 0.7354\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5410 - accuracy: 0.7357 - val_loss: 0.5391 - val_accuracy: 0.7359\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5395 - accuracy: 0.7359 - val_loss: 0.5419 - val_accuracy: 0.7354\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5399 - accuracy: 0.7365 - val_loss: 0.5425 - val_accuracy: 0.7357\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5395 - accuracy: 0.7359 - val_loss: 0.5407 - val_accuracy: 0.7365\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5399 - accuracy: 0.7368 - val_loss: 0.5408 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5389 - accuracy: 0.7371 - val_loss: 0.5408 - val_accuracy: 0.7380\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5406 - accuracy: 0.7353 - val_loss: 0.5433 - val_accuracy: 0.7359\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5393 - accuracy: 0.7371 - val_loss: 0.5399 - val_accuracy: 0.7367\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 2s 4ms/step - loss: 0.5381 - accuracy: 0.7361 - val_loss: 0.5419 - val_accuracy: 0.7380\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.5398 - accuracy: 0.7351 - val_loss: 0.5416 - val_accuracy: 0.7359\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.5382 - accuracy: 0.7362 - val_loss: 0.5415 - val_accuracy: 0.7346\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import and read the charity_data.csv\n",
    "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
    "application_df = pd.read_csv(url)\n",
    "\n",
    "# Create a new DataFrame with only the columns needed for modeling\n",
    "model_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
    "\n",
    "# Determine the number of unique values in each column\n",
    "unique_value_counts = model_df.nunique()\n",
    "\n",
    "# Binning for APPLICATION_TYPE column\n",
    "counts = model_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "application_types_to_replace = list(counts[counts < 500].index)\n",
    "model_df[\"APPLICATION_TYPE\"] = model_df[\"APPLICATION_TYPE\"].replace(application_types_to_replace, \"Other\")\n",
    "\n",
    "# Binning for CLASSIFICATION column\n",
    "counts_binning = model_df[\"CLASSIFICATION\"].value_counts()\n",
    "counts_classification = counts_binning[counts_binning > 1]\n",
    "classifications_to_replace = list(counts_binning[counts_binning < 100].index)\n",
    "model_df[\"CLASSIFICATION\"] = model_df[\"CLASSIFICATION\"].replace(classifications_to_replace, \"Other\")\n",
    "\n",
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "model_df = pd.get_dummies(model_df, dtype=np.float32, sparse=True)\n",
    "\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "y = model_df[\"IS_SUCCESSFUL\"].values\n",
    "X = model_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 256\n",
    "hidden_nodes_layer2 = 128\n",
    "hidden_nodes_layer3 = 64\n",
    "hidden_nodes_layer4 = 32\n",
    "nn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, validation_split=0.15, epochs=100, batch_size=64, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca10d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5540 - accuracy: 0.7290 - 698ms/epoch - 3ms/step\n",
      "Loss: 0.5539595484733582, Accuracy: 0.7289795875549316\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7538f4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {model_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7411d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increased the number of nodes in each hidden layer, adds a fourth hidden layer, \n",
    "# and changes the optimizer to Adam with a learning rate of 0.001. \n",
    "# Added a fourth hidden layer and increases the dropout rate to 0.2 to prevent overfitting. \n",
    "# Finally, it uses the same early stopping callback as before to stop the training if the validation loss does not improve \n",
    "# for 10 epochs. These changes should help improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81268fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model has 4 hidden layers with 256, 128, 64 and 32 nodes, respectively. \n",
    "# Added dropout layers to prevent overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
